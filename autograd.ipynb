{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f92ec3b-905d-4dde-9a53-39c2fc7f3d34",
   "metadata": {},
   "source": [
    "# Linear Regression implementation utilizing Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a770f1-457d-4874-b626-bc2cdc484006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/pj/.local/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/pj/.local/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /home/pj/.local/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /home/pj/.local/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /home/pj/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /home/pj/.local/lib/python3.10/site-packages (3.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/pj/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/pj/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: networkx in /home/pj/.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/pj/.local/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/pj/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /home/pj/.local/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/pj/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/pj/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/pj/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/pj/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pj/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: filelock in /home/pj/.local/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/pj/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: jinja2 in /home/pj/.local/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/pj/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/pj/.local/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/pj/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/pj/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/pj/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/pj/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pj/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/pj/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/pj/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/pj/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3/dist-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/pj/.local/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pj/.local/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/pj/.local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio scikit-learn numpy matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c028a145-b49f-4e63-9482-1d2cc625f536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee5fb9a1-c37f-482b-a4ad-c76a0a048da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Moving X, and y to GPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "scaler = StandardScaler()\n",
    "housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "X = torch.tensor(housing_data_plus_bias, dtype=torch.float32)\n",
    "y = torch.tensor(housing.target.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available. Moving X, and y to GPU\")\n",
    "    X = X.to(device='cuda')\n",
    "    y = y.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d97f59f-3a2d-4357-a579-0ff80a0b327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. to GPU\n",
      "Epoch 0, MSE = 8.881109237670898\n",
      "Epoch 100, MSE = 4.916640281677246\n",
      "Epoch 200, MSE = 4.81827974319458\n",
      "Epoch 300, MSE = 4.811000347137451\n",
      "Epoch 400, MSE = 4.808780193328857\n",
      "Epoch 500, MSE = 4.807347297668457\n",
      "Epoch 600, MSE = 4.806306838989258\n",
      "Epoch 700, MSE = 4.805540084838867\n",
      "Epoch 800, MSE = 4.804973602294922\n",
      "Epoch 900, MSE = 4.8045525550842285\n",
      "Epoch 1000, MSE = 4.804239749908447\n",
      "Epoch 1100, MSE = 4.8040056228637695\n",
      "Epoch 1200, MSE = 4.803830146789551\n",
      "Epoch 1300, MSE = 4.8036980628967285\n",
      "Epoch 1400, MSE = 4.803597927093506\n",
      "Epoch 1500, MSE = 4.803521156311035\n",
      "Epoch 1600, MSE = 4.803463459014893\n",
      "Epoch 1700, MSE = 4.8034186363220215\n",
      "Epoch 1800, MSE = 4.803383827209473\n",
      "Epoch 1900, MSE = 4.8033576011657715\n",
      "Epoch 2000, MSE = 4.803336143493652\n",
      "Epoch 2100, MSE = 4.803319931030273\n",
      "Epoch 2200, MSE = 4.803306579589844\n",
      "Epoch 2300, MSE = 4.80329704284668\n",
      "Epoch 2400, MSE = 4.803288459777832\n",
      "Epoch 2500, MSE = 4.803282260894775\n",
      "Epoch 2600, MSE = 4.803276538848877\n",
      "Epoch 2700, MSE = 4.803272724151611\n",
      "Epoch 2800, MSE = 4.803269386291504\n",
      "Epoch 2900, MSE = 4.803266525268555\n",
      "Epoch 3000, MSE = 4.803264141082764\n",
      "Epoch 3100, MSE = 4.803262233734131\n",
      "Epoch 3200, MSE = 4.8032612800598145\n",
      "Epoch 3300, MSE = 4.80325984954834\n",
      "Epoch 3400, MSE = 4.803258419036865\n",
      "Epoch 3500, MSE = 4.803257942199707\n",
      "Epoch 3600, MSE = 4.803256988525391\n",
      "Epoch 3700, MSE = 4.803256511688232\n",
      "Epoch 3800, MSE = 4.803256511688232\n",
      "Epoch 3900, MSE = 4.803255558013916\n",
      "Epoch 4000, MSE = 4.803255081176758\n",
      "Epoch 4100, MSE = 4.803255081176758\n",
      "Epoch 4200, MSE = 4.803255081176758\n",
      "Epoch 4300, MSE = 4.8032546043396\n",
      "Epoch 4400, MSE = 4.8032546043396\n",
      "Epoch 4500, MSE = 4.8032546043396\n",
      "Epoch 4600, MSE = 4.8032546043396\n",
      "Epoch 4700, MSE = 4.8032546043396\n",
      "Epoch 4800, MSE = 4.8032546043396\n",
      "Epoch 4900, MSE = 4.803254127502441\n",
      "Epoch 5000, MSE = 4.803254127502441\n",
      "Epoch 5100, MSE = 4.803253650665283\n",
      "Epoch 5200, MSE = 4.803254127502441\n",
      "Epoch 5300, MSE = 4.803253650665283\n",
      "Epoch 5400, MSE = 4.803254127502441\n",
      "Epoch 5500, MSE = 4.803254127502441\n",
      "Epoch 5600, MSE = 4.803254127502441\n",
      "Epoch 5700, MSE = 4.803253650665283\n",
      "Epoch 5800, MSE = 4.803254127502441\n",
      "Epoch 5900, MSE = 4.803253650665283\n",
      "Epoch 6000, MSE = 4.803253650665283\n",
      "Epoch 6100, MSE = 4.803253650665283\n",
      "Epoch 6200, MSE = 4.803253650665283\n",
      "Epoch 6300, MSE = 4.803253650665283\n",
      "Epoch 6400, MSE = 4.803253650665283\n",
      "Epoch 6500, MSE = 4.803253650665283\n",
      "Epoch 6600, MSE = 4.803254127502441\n",
      "Epoch 6700, MSE = 4.803253650665283\n",
      "Epoch 6800, MSE = 4.803254127502441\n",
      "Epoch 6900, MSE = 4.803253650665283\n",
      "Epoch 7000, MSE = 4.803253650665283\n",
      "Epoch 7100, MSE = 4.803253650665283\n",
      "Epoch 7200, MSE = 4.803253650665283\n",
      "Epoch 7300, MSE = 4.803253650665283\n",
      "Epoch 7400, MSE = 4.803253650665283\n",
      "Epoch 7500, MSE = 4.803253650665283\n",
      "Epoch 7600, MSE = 4.803253650665283\n",
      "Epoch 7700, MSE = 4.803253650665283\n",
      "Epoch 7800, MSE = 4.803253650665283\n",
      "Epoch 7900, MSE = 4.803254127502441\n",
      "Epoch 8000, MSE = 4.803253650665283\n",
      "Epoch 8100, MSE = 4.803253650665283\n",
      "Epoch 8200, MSE = 4.803253650665283\n",
      "Epoch 8300, MSE = 4.803253650665283\n",
      "Epoch 8400, MSE = 4.803253650665283\n",
      "Epoch 8500, MSE = 4.803253650665283\n",
      "Epoch 8600, MSE = 4.803253650665283\n",
      "Epoch 8700, MSE = 4.803253650665283\n",
      "Epoch 8800, MSE = 4.803253650665283\n",
      "Epoch 8900, MSE = 4.803253650665283\n",
      "Epoch 9000, MSE = 4.803253650665283\n",
      "Epoch 9100, MSE = 4.803254127502441\n",
      "Epoch 9200, MSE = 4.803253650665283\n",
      "Epoch 9300, MSE = 4.803254127502441\n",
      "Epoch 9400, MSE = 4.803254127502441\n",
      "Epoch 9500, MSE = 4.803254127502441\n",
      "Epoch 9600, MSE = 4.803254127502441\n",
      "Epoch 9700, MSE = 4.803254127502441\n",
      "Epoch 9800, MSE = 4.803254127502441\n",
      "Epoch 9900, MSE = 4.803254127502441\n",
      "Epoch 10000, MSE = 4.803254127502441\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Zero the gradients\n",
    "theta = 2 * (torch.rand(X.shape[1], 1, dtype=torch.float32) - 0.5)\n",
    "# theta.grad.zero_()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available. to GPU\")\n",
    "    theta = theta.to(device='cuda')\n",
    "\n",
    "theta.requires_grad_(True)\n",
    "\n",
    "for epoch in range(n_epochs + 1):\n",
    "    # Compute predictions\n",
    "    y_pred = X @ theta  # Matrix multiplication\n",
    "\n",
    "    # Compute error and MSE loss\n",
    "    error = y_pred - y\n",
    "    mse = (error ** 2).mean()\n",
    "\n",
    "    # Compute gradients\n",
    "    mse.backward()\n",
    "\n",
    "    # Update theta using gradient descent\n",
    "    with torch.no_grad():\n",
    "        theta -= learning_rate * theta.grad\n",
    "\n",
    "    # Zero the gradients\n",
    "    theta.grad.zero_()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, MSE = {mse.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "898b04ab-5bec-4476-9b83-f2a7c79245a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE = 17.94706916809082\n",
      "Epoch 100, MSE = 5.059835433959961\n",
      "Epoch 200, MSE = 4.846272945404053\n",
      "Epoch 300, MSE = 4.8298420906066895\n",
      "Epoch 400, MSE = 4.823822021484375\n",
      "Epoch 500, MSE = 4.819561004638672\n",
      "Epoch 600, MSE = 4.8162641525268555\n",
      "Epoch 700, MSE = 4.813679218292236\n",
      "Epoch 800, MSE = 4.811641693115234\n",
      "Epoch 900, MSE = 4.8100266456604\n",
      "Epoch 1000, MSE = 4.808741569519043\n",
      "Epoch 1100, MSE = 4.807713985443115\n",
      "Epoch 1200, MSE = 4.806889057159424\n",
      "Epoch 1300, MSE = 4.806224346160889\n",
      "Epoch 1400, MSE = 4.805686950683594\n",
      "Epoch 1500, MSE = 4.805250644683838\n",
      "Epoch 1600, MSE = 4.804895877838135\n",
      "Epoch 1700, MSE = 4.804605960845947\n",
      "Epoch 1800, MSE = 4.8043694496154785\n",
      "Epoch 1900, MSE = 4.804174900054932\n",
      "Epoch 2000, MSE = 4.804015159606934\n",
      "Epoch 2100, MSE = 4.803884029388428\n",
      "Epoch 2200, MSE = 4.803775787353516\n",
      "Epoch 2300, MSE = 4.803686618804932\n",
      "Epoch 2400, MSE = 4.80361270904541\n",
      "Epoch 2500, MSE = 4.803552150726318\n",
      "Epoch 2600, MSE = 4.803501129150391\n",
      "Epoch 2700, MSE = 4.803459167480469\n",
      "Epoch 2800, MSE = 4.803424835205078\n",
      "Epoch 2900, MSE = 4.803396224975586\n",
      "Epoch 3000, MSE = 4.803372383117676\n",
      "Epoch 3100, MSE = 4.803351879119873\n",
      "Epoch 3200, MSE = 4.803335666656494\n",
      "Epoch 3300, MSE = 4.803321838378906\n",
      "Epoch 3400, MSE = 4.803310394287109\n",
      "Epoch 3500, MSE = 4.803300857543945\n",
      "Epoch 3600, MSE = 4.803293228149414\n",
      "Epoch 3700, MSE = 4.803286075592041\n",
      "Epoch 3800, MSE = 4.803281307220459\n",
      "Epoch 3900, MSE = 4.803276538848877\n",
      "Epoch 4000, MSE = 4.803272724151611\n",
      "Epoch 4100, MSE = 4.803269386291504\n",
      "Epoch 4200, MSE = 4.803266525268555\n",
      "Epoch 4300, MSE = 4.803264617919922\n",
      "Epoch 4400, MSE = 4.803262710571289\n",
      "Epoch 4500, MSE = 4.8032612800598145\n",
      "Epoch 4600, MSE = 4.803260326385498\n",
      "Epoch 4700, MSE = 4.803258895874023\n",
      "Epoch 4800, MSE = 4.803258419036865\n",
      "Epoch 4900, MSE = 4.803257465362549\n",
      "Epoch 5000, MSE = 4.803256988525391\n",
      "Epoch 5100, MSE = 4.803256511688232\n",
      "Epoch 5200, MSE = 4.803256034851074\n",
      "Epoch 5300, MSE = 4.803256034851074\n",
      "Epoch 5400, MSE = 4.803255081176758\n",
      "Epoch 5500, MSE = 4.803255081176758\n",
      "Epoch 5600, MSE = 4.8032546043396\n",
      "Epoch 5700, MSE = 4.8032546043396\n",
      "Epoch 5800, MSE = 4.8032546043396\n",
      "Epoch 5900, MSE = 4.8032546043396\n",
      "Epoch 6000, MSE = 4.8032546043396\n",
      "Epoch 6100, MSE = 4.8032546043396\n",
      "Epoch 6200, MSE = 4.803254127502441\n",
      "Epoch 6300, MSE = 4.803254127502441\n",
      "Epoch 6400, MSE = 4.8032546043396\n",
      "Epoch 6500, MSE = 4.803254127502441\n",
      "Epoch 6600, MSE = 4.8032546043396\n",
      "Epoch 6700, MSE = 4.803253650665283\n",
      "Epoch 6800, MSE = 4.803254127502441\n",
      "Epoch 6900, MSE = 4.803254127502441\n",
      "Epoch 7000, MSE = 4.803253650665283\n",
      "Epoch 7100, MSE = 4.803254127502441\n",
      "Epoch 7200, MSE = 4.803254127502441\n",
      "Epoch 7300, MSE = 4.803253650665283\n",
      "Epoch 7400, MSE = 4.803253650665283\n",
      "Epoch 7500, MSE = 4.803253650665283\n",
      "Epoch 7600, MSE = 4.803253650665283\n",
      "Epoch 7700, MSE = 4.803254127502441\n",
      "Epoch 7800, MSE = 4.803254127502441\n",
      "Epoch 7900, MSE = 4.803253650665283\n",
      "Epoch 8000, MSE = 4.803254127502441\n",
      "Epoch 8100, MSE = 4.803253650665283\n",
      "Epoch 8200, MSE = 4.803253650665283\n",
      "Epoch 8300, MSE = 4.803253650665283\n",
      "Epoch 8400, MSE = 4.803253650665283\n",
      "Epoch 8500, MSE = 4.803253650665283\n",
      "Epoch 8600, MSE = 4.803253650665283\n",
      "Epoch 8700, MSE = 4.803254127502441\n",
      "Epoch 8800, MSE = 4.803253650665283\n",
      "Epoch 8900, MSE = 4.803253650665283\n",
      "Epoch 9000, MSE = 4.803253650665283\n",
      "Epoch 9100, MSE = 4.803253650665283\n",
      "Epoch 9200, MSE = 4.803253650665283\n",
      "Epoch 9300, MSE = 4.803253650665283\n",
      "Epoch 9400, MSE = 4.803253650665283\n",
      "Epoch 9500, MSE = 4.803254127502441\n",
      "Epoch 9600, MSE = 4.803253650665283\n",
      "Epoch 9700, MSE = 4.803253650665283\n",
      "Epoch 9800, MSE = 4.803253650665283\n",
      "Epoch 9900, MSE = 4.803253650665283\n",
      "Epoch 10000, MSE = 4.803253650665283\n",
      "Optimized Theta: [[ 0.6389724 ]\n",
      " [ 0.82964313]\n",
      " [ 0.11875587]\n",
      " [-0.2655715 ]\n",
      " [ 0.30573288]\n",
      " [-0.00450168]\n",
      " [-0.0393272 ]\n",
      " [-0.89983255]\n",
      " [-0.87049145]]\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "n_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize theta as a trainable parameter\n",
    "theta = torch.randn((X.shape[1], 1), dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "\n",
    "# Define optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.SGD([theta], lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs + 1):\n",
    "    # Compute predictions\n",
    "    y_pred = X @ theta  # Matrix multiplication\n",
    "\n",
    "    # Compute loss (Mean Squared Error)\n",
    "    mse = (y_pred - y).pow(2).mean()\n",
    "\n",
    "    # Zero the gradients before backpropagation\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute gradients via backpropagation\n",
    "    mse.backward()\n",
    "\n",
    "    # Update theta using optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, MSE = {mse.item()}\")\n",
    "\n",
    "# Final optimized theta\n",
    "best_theta = theta.detach().cpu().numpy()\n",
    "print(\"Optimized Theta:\", best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "822b1db7-2a84-4e47-8ddd-e6f615858bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE = 6.470011234283447\n",
      "Epoch 100, MSE = 5.432498931884766\n",
      "Epoch 200, MSE = 4.13297700881958\n",
      "Epoch 300, MSE = 3.7448270320892334\n",
      "Epoch 400, MSE = 4.711345672607422\n",
      "Epoch 500, MSE = 4.623612403869629\n",
      "Epoch 600, MSE = 4.4607744216918945\n",
      "Epoch 700, MSE = 5.024688720703125\n",
      "Epoch 800, MSE = 5.540892124176025\n",
      "Epoch 900, MSE = 3.9796359539031982\n",
      "Epoch 1000, MSE = 5.572781562805176\n",
      "Epoch 1100, MSE = 3.4575204849243164\n",
      "Epoch 1200, MSE = 4.971525192260742\n",
      "Epoch 1300, MSE = 6.160943984985352\n",
      "Epoch 1400, MSE = 4.750181674957275\n",
      "Epoch 1500, MSE = 5.0050554275512695\n",
      "Epoch 1600, MSE = 7.139811038970947\n",
      "Epoch 1700, MSE = 3.919447422027588\n",
      "Epoch 1800, MSE = 6.097949028015137\n",
      "Epoch 1900, MSE = 4.586579322814941\n",
      "Epoch 2000, MSE = 4.15958309173584\n",
      "Epoch 2100, MSE = 4.3302741050720215\n",
      "Epoch 2200, MSE = 5.279644012451172\n",
      "Epoch 2300, MSE = 4.347583770751953\n",
      "Epoch 2400, MSE = 5.252175331115723\n",
      "Epoch 2500, MSE = 4.770808219909668\n",
      "Epoch 2600, MSE = 4.795855522155762\n",
      "Epoch 2700, MSE = 5.189198970794678\n",
      "Epoch 2800, MSE = 5.251859188079834\n",
      "Epoch 2900, MSE = 4.521000385284424\n",
      "Epoch 3000, MSE = 4.9722795486450195\n",
      "Epoch 3100, MSE = 5.095044136047363\n",
      "Epoch 3200, MSE = 5.462499141693115\n",
      "Epoch 3300, MSE = 5.2911529541015625\n",
      "Epoch 3400, MSE = 5.747422695159912\n",
      "Epoch 3500, MSE = 4.235566139221191\n",
      "Epoch 3600, MSE = 4.423484802246094\n",
      "Epoch 3700, MSE = 4.946499824523926\n",
      "Epoch 3800, MSE = 4.35289192199707\n",
      "Epoch 3900, MSE = 4.3285698890686035\n",
      "Epoch 4000, MSE = 4.2638325691223145\n",
      "Epoch 4100, MSE = 3.7211289405822754\n",
      "Epoch 4200, MSE = 5.7052435874938965\n",
      "Epoch 4300, MSE = 4.852948188781738\n",
      "Epoch 4400, MSE = 4.869344234466553\n",
      "Epoch 4500, MSE = 4.63227653503418\n",
      "Epoch 4600, MSE = 5.66994047164917\n",
      "Epoch 4700, MSE = 4.840994834899902\n",
      "Epoch 4800, MSE = 3.6686410903930664\n",
      "Epoch 4900, MSE = 5.059452056884766\n",
      "Epoch 5000, MSE = 4.274999141693115\n",
      "Epoch 5100, MSE = 4.8867902755737305\n",
      "Epoch 5200, MSE = 6.68997859954834\n",
      "Epoch 5300, MSE = 6.036646842956543\n",
      "Epoch 5400, MSE = 5.561196804046631\n",
      "Epoch 5500, MSE = 5.215824127197266\n",
      "Epoch 5600, MSE = 5.620119094848633\n",
      "Epoch 5700, MSE = 4.612310886383057\n",
      "Epoch 5800, MSE = 4.616692543029785\n",
      "Epoch 5900, MSE = 5.063018798828125\n",
      "Epoch 6000, MSE = 5.236871719360352\n",
      "Epoch 6100, MSE = 4.824038982391357\n",
      "Epoch 6200, MSE = 4.272022247314453\n",
      "Epoch 6300, MSE = 5.062897682189941\n",
      "Epoch 6400, MSE = 4.6280517578125\n",
      "Epoch 6500, MSE = 5.49269437789917\n",
      "Epoch 6600, MSE = 4.518424034118652\n",
      "Epoch 6700, MSE = 4.283511161804199\n",
      "Epoch 6800, MSE = 4.787258148193359\n",
      "Epoch 6900, MSE = 4.804243564605713\n",
      "Epoch 7000, MSE = 4.280359268188477\n",
      "Epoch 7100, MSE = 4.752686500549316\n",
      "Epoch 7200, MSE = 5.011418342590332\n",
      "Epoch 7300, MSE = 5.103832244873047\n",
      "Epoch 7400, MSE = 5.099595546722412\n",
      "Epoch 7500, MSE = 4.358121395111084\n",
      "Epoch 7600, MSE = 4.533202171325684\n",
      "Epoch 7700, MSE = 4.270759582519531\n",
      "Epoch 7800, MSE = 6.218297958374023\n",
      "Epoch 7900, MSE = 4.860021591186523\n",
      "Epoch 8000, MSE = 4.2575273513793945\n",
      "Epoch 8100, MSE = 5.793156623840332\n",
      "Epoch 8200, MSE = 6.205418586730957\n",
      "Epoch 8300, MSE = 4.745694160461426\n",
      "Epoch 8400, MSE = 5.404630661010742\n",
      "Epoch 8500, MSE = 4.2039995193481445\n",
      "Epoch 8600, MSE = 4.551958084106445\n",
      "Epoch 8700, MSE = 4.29637336730957\n",
      "Epoch 8800, MSE = 4.529449462890625\n",
      "Epoch 8900, MSE = 4.667689800262451\n",
      "Epoch 9000, MSE = 4.421128749847412\n",
      "Epoch 9100, MSE = 4.4504804611206055\n",
      "Epoch 9200, MSE = 4.963191032409668\n",
      "Epoch 9300, MSE = 3.870675563812256\n",
      "Epoch 9400, MSE = 4.925646781921387\n",
      "Epoch 9500, MSE = 5.608904838562012\n",
      "Epoch 9600, MSE = 5.177983283996582\n",
      "Epoch 9700, MSE = 4.9384846687316895\n",
      "Epoch 9800, MSE = 4.780799865722656\n",
      "Epoch 9900, MSE = 4.788341045379639\n",
      "Epoch 10000, MSE = 5.1296916007995605\n",
      "Optimized Theta: [[-0.30506563]\n",
      " [ 0.8287221 ]\n",
      " [ 0.11908639]\n",
      " [-0.26327085]\n",
      " [ 0.30476865]\n",
      " [-0.00342436]\n",
      " [-0.03797541]\n",
      " [-0.8991267 ]\n",
      " [-0.8720463 ]]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "batch_size = 128  # Define mini-batch size\n",
    "\n",
    "# Create mini-batch DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize theta as a trainable parameter\n",
    "theta = torch.randn((X.shape[1], 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "\n",
    "# Define optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.SGD([theta], lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs + 1):\n",
    "    for batch_X, batch_y in dataloader:  # Iterate over mini-batches\n",
    "        # Compute predictions\n",
    "        y_pred = batch_X @ theta  # Matrix multiplication\n",
    "\n",
    "        # Compute loss (Mean Squared Error)\n",
    "        mse = (y_pred - batch_y).pow(2).mean()\n",
    "\n",
    "        # Zero the gradients before backpropagation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute gradients via backpropagation\n",
    "        mse.backward()\n",
    "\n",
    "        # Update theta using optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, MSE = {mse.item()}\")\n",
    "\n",
    "# Final optimized theta\n",
    "best_theta = theta.detach().cpu().numpy()\n",
    "print(\"Optimized Theta:\", best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531afdf-9c05-4674-8710-c40c90bcebd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
